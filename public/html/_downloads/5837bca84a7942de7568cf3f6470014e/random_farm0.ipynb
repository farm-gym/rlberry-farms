{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nRandom agent on Farm0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from rlberry.agents import AgentWithSimplePolicy\nfrom rlberry.manager import AgentManager, evaluate_agents, plot_writer_data\nfrom rlberry_farms.game0_env import Farm0\nfrom rlberry.agents.torch.utils.training import model_factory_from_env\nimport numpy as np\n\nenv_ctor, env_kwargs = Farm0, {}\n\nclass RandomAgent(AgentWithSimplePolicy):\n    name = \"RandomAgent\"\n\n    def __init__(self, env, **kwargs):\n        AgentWithSimplePolicy.__init__(self, env, **kwargs)\n\n    def fit(self, budget=100, **kwargs):\n        observation = self.env.reset()\n        episode_reward = 0\n        for ep in range(int(budget)):\n            action = self.policy(observation)\n            observation, reward, done, _ = self.env.step(action)\n            episode_reward += reward\n            if done:\n                self.writer.add_scalar('episode_rewards', episode_reward, ep)\n                episode_reward = 0\n                self.env.reset()\n            \n    def policy(self, observation):\n        return self.env.action_space.sample()  # choose an action at random\n\nif __name__ == \"__main__\":\n    manager = AgentManager(RandomAgent,\n                           (env_ctor, env_kwargs),\n                        agent_name=\"RandomAgent\",\n                        fit_budget=3e5,\n                        eval_kwargs=dict(eval_horizon=365),\n                        n_fit=4,\n                        parallelization=\"process\",\n                        mp_context=\"spawn\",\n                        output_dir=\"random_results\",\n                    )\n    manager.fit()\n    evaluation = evaluate_agents([manager], n_simulations=128, show=False).values\n    np.savetxt('random_farm0.out', np.array(evaluation), delimiter=',')\n    data = plot_writer_data(\"random_results\",\"episode_rewards\", smooth_weight = 0.95)\n    \n\n# This template file gives mean evaluation reward 275 and std 96."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}